# üìß Classificador de E-mails com IA e Sugest√£o de Respostas

Este projeto √© uma aplica√ß√£o web simples desenvolvida em **Python (Flask)** que utiliza **Intelig√™ncia Artificial** para classificar e-mails em categorias "Produtivo" ou "Improdutivo" e, em seguida, sugerir respostas autom√°ticas personalizadas. A intelig√™ncia de gera√ß√£o de respostas √© **powered by OpenAI GPT-3.5 Turbo**.

-----

## ‚ú® **Funcionalidades**

  * **Interface Web Intuitiva:** Um formul√°rio HTML permite o upload de arquivos `.txt` ou `.pdf` ou a inser√ß√£o direta do conte√∫do do e-mail.
  * **Classifica√ß√£o de E-mails:** Categoriza e-mails em:
      * **Produtivo:** E-mails que exigem a√ß√£o ou resposta (ex: solicita√ß√µes, d√∫vidas, suporte t√©cnico).
      * **Improdutivo:** E-mails que n√£o demandam a√ß√£o imediata (ex: agradecimentos, felicita√ß√µes).
  * **Gera√ß√£o de Respostas Autom√°ticas Inteligentes:** Utiliza a **API da OpenAI (GPT-3.5 Turbo)** para gerar sugest√µes de respostas contextuais, fluentes e adequadas √† categoria identificada do e-mail, otimizando seu tempo de resposta.
  * **Processamento de Arquivos:** Capacidade de extrair texto de arquivos `.txt` e `.pdf` para an√°lise.
  * **Pr√©-processamento B√°sico:** Realiza um pr√©-processamento simples do texto para normaliza√ß√£o antes da an√°lise.

-----

## üõ†Ô∏è **Tecnologias Utilizadas**

  * **Backend:**
      * **Python:** Linguagem de programa√ß√£o principal.
      * **Flask:** Microframework web para Python.
      * **OpenAI API:** Principal motor para a **gera√ß√£o de respostas autom√°ticas (GPT-3.5 Turbo)**.
      * **PyPDF2:** Para extra√ß√£o de texto de arquivos PDF.
      * **Gunicorn:** Servidor WSGI utilizado para servir a aplica√ß√£o Flask em ambiente de produ√ß√£o (Vercel).
      * **python-dotenv:** Para carregamento de vari√°veis de ambiente em desenvolvimento local.
  * **Frontend:**
      * **HTML:** Estrutura da interface.
      * **CSS:** Estiliza√ß√£o b√°sica para uma boa experi√™ncia visual.
      * **JavaScript (Fetch API):** Para comunica√ß√£o ass√≠ncrona com o backend e exibi√ß√£o din√¢mica dos resultados.
  * **Deploy:**
      * **Vercel:** Plataforma de deploy que hospeda a aplica√ß√£o como uma *Serverless Function*.

-----

## üöÄ **Como Rodar o Projeto Localmente**

Siga os passos abaixo para configurar e executar a aplica√ß√£o em sua m√°quina.

### **Pr√©-requisitos**

  * **Python 3.8+** (Recomenda-se Python 3.10 para compatibilidade com Vercel)
  * **Git**
  * **Chave de API da OpenAI:** Essencial para a funcionalidade de gera√ß√£o de respostas. Obtenha uma em [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys).

### **Passos para Configura√ß√£o**

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone https://github.com/SEU_USUARIO_GITHUB/SEU_REPOSITORIO.git
    cd SEU_REPOSITORIO
    ```

    (Substitua `SEU_USUARIO_GITHUB` e `SEU_REPOSITORIO` pelos seus dados reais do GitHub).

2.  **Crie e ative um ambiente virtual (altamente recomendado):**

    ```bash
    python -m venv venv
    # No Windows:
    .\venv\Scripts\activate
    # No macOS/Linux:
    source venv/bin/activate
    ```

3.  **Instale as depend√™ncias:**

    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure sua chave de API da OpenAI:**

    Crie um arquivo chamado `.env` na **raiz do projeto** (na mesma pasta de `vercel.json`) com o seguinte conte√∫do:

    ```
    OPENAI_API_KEY="sua_chave_secreta_da_openai_aqui"
    ```

    **Importante:** Substitua `"sua_chave_secreta_da_openai_aqui"` pela sua chave real da OpenAI. **Garanta que o arquivo `.env` esteja listado no seu `.gitignore` para evitar que sua chave seja enviada para o reposit√≥rio p√∫blico\!**

5.  **Execute a aplica√ß√£o Flask:**

    ```bash
    python api/index.py
    ```

6.  **Acesse a aplica√ß√£o:**
    Abra seu navegador e acesse: `http://127.0.0.1:5000/`

-----

## ‚òÅÔ∏è **Deploy na Vercel**

Esta aplica√ß√£o est√° configurada para ser facilmente implantada na Vercel como uma *Serverless Function*.

### **Estrutura de Pastas para Deploy**

Para que a Vercel detecte e fa√ßa o deploy corretamente, o c√≥digo Flask principal foi movido para `api/index.py`, e os arquivos de template e est√°ticos s√£o referenciados de l√°. A estrutura esperada √©:

```
seu_projeto/
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ index.py  # Ponto de entrada da aplica√ß√£o Flask na Vercel
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îî‚îÄ‚îÄ style.css
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ vercel.json     # Configura√ß√µes de build e rotas da Vercel
‚îî‚îÄ‚îÄ .gitignore
```

### **Passos para o Deploy na Vercel**

1.  **Crie uma Conta Vercel:** Se ainda n√£o tiver, registre-se em [vercel.com](https://vercel.com/).

2.  **Conecte seu Reposit√≥rio Git:** No painel da Vercel, importe seu reposit√≥rio GitHub.

3.  **Configure as Vari√°veis de Ambiente:** Durante a configura√ß√£o do projeto na Vercel, v√° em "Environment Variables" e adicione:

      * **Name:** `OPENAI_API_KEY`
      * **Value:** `SUA_CHAVE_SECRETA_DA_OPENAI_AQUI`
      * Esta etapa √© **CR√çTICA** para que a funcionalidade da OpenAI funcione em produ√ß√£o, pois a Vercel n√£o l√™ o arquivo `.env`.

4.  **Configure as Regras de Build e Rotas:** O arquivo `vercel.json` na raiz do seu projeto j√° cont√©m as configura√ß√µes necess√°rias para a Vercel construir o projeto Python, servir os arquivos est√°ticos e rotear as requisi√ß√µes para a *serverless function* Flask.

    ```json
    {
      "version": 2,
      "builds": [
        {
          "src": "api/index.py",
          "use": "@vercel/python",
          "config": {
            "maxLambdaSize": "15mb",
            "runtime": "python3.10"
          }
        },
        {
          "src": "index.html",
          "use": "@vercel/static"
        },
        {
          "src": "static/**",
          "use": "@vercel/static"
        }
      ],
      "routes": [
        {
          "src": "/static/(.*)",
          "dest": "/static/$1"
        },
        {
          "src": "/(.*)",
          "dest": "/api/index.py"
        }
      ],
      "installCommand": "pip install -r requirements.txt"
    }
    ```

5.  **Inicie o Deploy:** Ap√≥s configurar as vari√°veis de ambiente, clique em "Deploy". A Vercel far√° o restante, e voc√™ receber√° uma URL para sua aplica√ß√£o online quando o processo for conclu√≠do.

-----

## üí° **Como Funciona a Classifica√ß√£o e Resposta Detalhadamente**

  * **Classifica√ß√£o (Simulada):** Atualmente, a categoriza√ß√£o entre "Produtivo" e "Improdutivo" √© baseada na detec√ß√£o de palavras-chave predefinidas no conte√∫do do e-mail (ex: "solicita√ß√£o", "d√∫vida", "suporte" indicam um e-mail "Produtivo"). Embora eficaz para demonstra√ß√£o, esta abordagem pode ser expandida com um modelo de NLP treinado para maior precis√£o em cen√°rios reais.
  * **Gera√ß√£o de Resposta (OpenAI - GPT-3.5 Turbo):**
    1.  O conte√∫do do e-mail e sua categoria (Produtivo/Improdutivo) s√£o enviados como parte de um **prompt** estruturado para a API da OpenAI.
    2.  Modelos como o `gpt-3.5-turbo` analisam o prompt e o contexto do e-mail.
    3.  Com base em instru√ß√µes claras no prompt (ex: "seja formal e conciso para emails produtivos", "seja curto e cordial para improdutivos"), a OpenAI gera uma sugest√£o de resposta que √© ent√£o exibida na interface web.
    4.  A API √© configurada para otimizar o comprimento e o tom da resposta, fornecendo um ponto de partida √∫til para o usu√°rio.

-----

## ‚è≠Ô∏è **Pr√≥ximos Passos e Melhorias Potenciais**

  * **Classifica√ß√£o Aprimorada:** Treinar um modelo de classifica√ß√£o de texto (ex: com Hugging Face Transformers) utilizando um dataset real de e-mails rotulados para alcan√ßar maior precis√£o e robustez na categoriza√ß√£o.
  * **Pr√©-processamento Avan√ßado:** Integrar bibliotecas de NLP como `NLTK` ou `SpaCy` para um pr√©-processamento mais sofisticado do texto (remo√ß√£o de *stopwords*, lematiza√ß√£o/stemming, reconhecimento de entidades nomeadas), o que pode melhorar a performance dos modelos de IA.
  * **Interface do Usu√°rio (UX):**
      * Adicionar funcionalidade de arrastar e soltar arquivos para um upload mais fluido.
      * Melhorar o feedback visual ao usu√°rio durante o processamento (ex: barra de progresso mais detalhada).
      * Implementar um hist√≥rico de e-mails processados e suas respectivas respostas.
  * **Personaliza√ß√£o:** Permitir que o usu√°rio defina ou ajuste palavras-chave e regras de classifica√ß√£o, ou personalize os prompts de resposta para a OpenAI.
  * **Integra√ß√£o com Contas de E-mail:** Desenvolver funcionalidades para que a aplica√ß√£o possa ler e-mails diretamente de uma caixa de entrada (ex: Gmail, Outlook) ap√≥s a devida autentica√ß√£o e autoriza√ß√£o.
  * **Autentica√ß√£o e Seguran√ßa:** Para um ambiente de produ√ß√£o mais robusto, adicionar um sistema de autentica√ß√£o de usu√°rio e implementar medidas de seguran√ßa adicionais para a API e os dados.

-----

## ü§ù **Contribui√ß√£o**

Sinta-se √† vontade para contribuir com este projeto\!

1.  Fa√ßa um *fork* do reposit√≥rio.
2.  Crie uma *branch* para sua funcionalidade (`git checkout -b minha-nova-funcionalidade`).
3.  Fa√ßa suas altera√ß√µes e *commit* (`git commit -m 'Adiciona nova funcionalidade X'`).
4.  Envie para sua *branch* (`git push origin minha-nova-funcionalidade`).
5.  Abra um *Pull Request* detalhando suas mudan√ßas.

-----

## üìÑ **Licen√ßa**

Este projeto est√° sob a licen√ßa [MIT License](https://www.google.com/search?q=LICENSE).

-----
